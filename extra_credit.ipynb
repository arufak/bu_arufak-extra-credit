{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (370703, 24)\n",
      "Test set shape: (92676, 23)\n",
      "Preprocessing training data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ... (previous imports remain the same)\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        self.scaler = None\n",
    "        \n",
    "    def preprocess(self, df, training=True):\n",
    "        print(f\"Preprocessing {'training' if training else 'test'} data...\")\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Time features\n",
    "        df['datetime'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "        df['hour'] = df['datetime'].dt.hour\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "        df['is_night'] = df['hour'].isin(list(range(23)) + list(range(0, 5))).astype(int)\n",
    "        df['is_business_hour'] = df['hour'].isin(range(9, 18)).astype(int)\n",
    "        \n",
    "        # Location features\n",
    "        df['distance'] = np.sqrt(\n",
    "            ((df['lat'] - df['merch_lat']) ** 2) + \n",
    "            ((df['long'] - df['merch_long']) ** 2)\n",
    "        )\n",
    "        \n",
    "        # Amount features\n",
    "        df['log_amount'] = np.log1p(df['amt'])\n",
    "        df['amount_per_pop'] = df['amt'] / (df['city_pop'] + 1)\n",
    "        \n",
    "        if training:\n",
    "            # Simplified statistics calculations\n",
    "            self.category_mean = df.groupby('category')['amt'].mean()\n",
    "            self.category_std = df.groupby('category')['amt'].std()\n",
    "            self.category_risk = df.groupby('category')['is_fraud'].mean()\n",
    "            \n",
    "            self.merchant_mean = df.groupby('merchant')['amt'].mean()\n",
    "            self.merchant_std = df.groupby('merchant')['amt'].std()\n",
    "            self.merchant_risk = df.groupby('merchant')['is_fraud'].mean()\n",
    "            \n",
    "            self.hour_mean = df.groupby('hour')['amt'].mean()\n",
    "            self.hour_std = df.groupby('hour')['amt'].std()\n",
    "            self.hour_risk = df.groupby('hour')['is_fraud'].mean()\n",
    "        \n",
    "        # Map features\n",
    "        df['category_mean_amt'] = df['category'].map(self.category_mean).fillna(0)\n",
    "        df['category_std_amt'] = df['category'].map(self.category_std).fillna(0)\n",
    "        df['category_risk'] = df['category'].map(self.category_risk).fillna(0)\n",
    "        \n",
    "        df['merchant_mean_amt'] = df['merchant'].map(self.merchant_mean).fillna(0)\n",
    "        df['merchant_std_amt'] = df['merchant'].map(self.merchant_std).fillna(0)\n",
    "        df['merchant_risk'] = df['merchant'].map(self.merchant_risk).fillna(0)\n",
    "        \n",
    "        df['hour_mean_amt'] = df['hour'].map(self.hour_mean).fillna(0)\n",
    "        df['hour_std_amt'] = df['hour'].map(self.hour_std).fillna(0)\n",
    "        df['hour_risk'] = df['hour'].map(self.hour_risk).fillna(0)\n",
    "        \n",
    "        # Risk scores\n",
    "        df['amount_risk_score'] = df['log_amount'] * df['category_risk']\n",
    "        df['amount_merchant_risk'] = df['log_amount'] * df['merchant_risk']\n",
    "        df['time_risk_score'] = df['hour_risk'] * df['category_risk']\n",
    "        \n",
    "        # Transaction patterns\n",
    "        df['tx_count_hour'] = df.groupby(['cc_num', 'hour'])['datetime'].transform('count')\n",
    "        df['tx_count_day'] = df.groupby(['cc_num', 'day'])['datetime'].transform('count')\n",
    "        \n",
    "        numerical_features = [\n",
    "            'amt', 'log_amount', 'distance', 'amount_per_pop',\n",
    "            'hour', 'day', 'month', 'day_of_week', 'is_weekend',\n",
    "            'is_night', 'is_business_hour',\n",
    "            'category_mean_amt', 'category_std_amt', 'category_risk',\n",
    "            'merchant_mean_amt', 'merchant_std_amt', 'merchant_risk',\n",
    "            'hour_mean_amt', 'hour_std_amt', 'hour_risk',\n",
    "            'amount_risk_score', 'amount_merchant_risk', 'time_risk_score',\n",
    "            'tx_count_hour', 'tx_count_day',\n",
    "            'city_pop', 'lat', 'long', 'merch_lat', 'merch_long'\n",
    "        ]\n",
    "        \n",
    "        categorical_features = ['category', 'gender', 'state', 'job']\n",
    "        \n",
    "        # Encode categorical features\n",
    "        for col in categorical_features:\n",
    "            if training:\n",
    "                le = LabelEncoder()\n",
    "                df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "                self.encoders[col] = le\n",
    "            else:\n",
    "                le = self.encoders[col]\n",
    "                df[col] = df[col].map(lambda x: 'unknown' if x not in le.classes_ else x)\n",
    "                df[col + '_encoded'] = le.transform(df[col])\n",
    "            numerical_features.append(col + '_encoded')\n",
    "        \n",
    "        X = df[numerical_features].fillna(0)\n",
    "        \n",
    "        if training:\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            y = df['is_fraud']\n",
    "            return X_scaled, y\n",
    "        return self.scaler.transform(X)\n",
    "\n",
    "# Load and preprocess data\n",
    "train_df = pd.read_csv(r\"C:\\Users\\arufa\\Documents\\CS506\\EXTRA_CREDIT\\train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\arufa\\Documents\\CS506\\EXTRA_CREDIT\\test.csv\")\n",
    "\n",
    "print(\"\\nTraining set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "# Preprocess data\n",
    "preprocessor = DataPreprocessor()\n",
    "X, y = preprocessor.preprocess(train_df, training=True)\n",
    "\n",
    "# Create XGBoost with proven parameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight = len(y[y == 0]) / len(y[y == 1]) * 1.2 ,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=1000,  # Updated\n",
    "    max_depth=12,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=0.08,\n",
    "    reg_lambda=0.8,\n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Fast cross-validation\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    score = f1_score(y_val, y_pred)\n",
    "    scores.append(score)\n",
    "    print(f\"\\nFold {fold} F1-score: {score:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(f\"\\nAverage CV F1-score: {np.mean(scores):.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "X_test = preprocessor.preprocess(test_df, training=False)\n",
    "test_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'is_fraud': test_predictions\n",
    "})\n",
    "\n",
    "submission_path = r\"C:\\Users\\arufa\\Documents\\CS506\\EXTRA_CREDIT\\submission5.csv\"\n",
    "submission.to_csv(submission_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
